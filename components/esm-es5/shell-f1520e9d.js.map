{"version":3,"sources":["node_modules/@codemirror/legacy-modes/mode/shell.js"],"names":["words","define","style","dict","i","length","commonAtoms","commonKeywords","commonCommands","tokenBase","stream","state","eatSpace","sol","ch","next","tokens","unshift","tokenString","tokenize","eat","skipToEnd","tokenDollar","eatWhile","match","heredoc","tokenHeredoc","test","eol","peek","cur","current","hasOwnProperty","quote","close","escaped","shift","backUp","tokenStringStart","delim","string","shell","startState","token","languageData","autocomplete","concat","closeBrackets","brackets","commentTokens","line"],"mappings":"AAAA,IAAIA,MAAQ,GACZ,SAASC,OAAOC,EAAOC,GACrB,IAAI,IAAIC,EAAI,EAAGA,EAAID,EAAKE,OAAQD,IAAK,CACnCJ,MAAMG,EAAKC,IAAMF,GAIrB,IAAII,YAAc,CAAC,OAAQ,SAC3B,IAAIC,eAAiB,CAAC,KAAM,OAAQ,KAAM,OAAQ,OAAQ,QAAS,QAAS,MAAO,KAAM,OAAQ,KAC3E,MAAO,MAAO,OAAQ,OAAQ,MAAO,QAAS,SAAU,YAC9E,IAAIC,eAAiB,CAAC,KAAM,MAAO,OAAQ,OAAQ,MAAO,KAAM,KAAM,QAAS,QAAS,SAAU,QAC5E,KAAM,OAAQ,MAAO,OAAQ,OAAQ,OAAQ,OAAQ,MAAO,MAAO,MAAO,OAAQ,KAAM,OAAQ,UAChG,KAAM,KAAM,OAAQ,QAAS,UAAW,KAAM,KAAM,KAAM,OAAQ,MAAO,OAAQ,KAAM,UAAW,KAClG,QAAS,MAAO,UAAW,KAAM,QAAS,QAAS,SAAU,OAAQ,QAAS,MAAO,QAAS,OAC9F,KAAM,OAAQ,MAAO,MAAO,SAAU,MAAO,QAAS,KAAM,MAAO,OAAQ,KAAM,OAAQ,MAAO,QAChG,MAAO,OAE7BP,OAAO,OAAQK,aACfL,OAAO,UAAWM,gBAClBN,OAAO,UAAWO,gBAElB,SAASC,UAAUC,EAAQC,GACzB,GAAID,EAAOE,WAAY,OAAO,KAE9B,IAAIC,EAAMH,EAAOG,MACjB,IAAIC,EAAKJ,EAAOK,OAEhB,GAAID,IAAO,KAAM,CACfJ,EAAOK,OACP,OAAO,KAET,GAAID,IAAO,KAAQA,IAAO,KAAOA,IAAO,IAAK,CAC3CH,EAAMK,OAAOC,QAAQC,YAAYJ,EAAIA,IAAO,IAAM,QAAU,WAC5D,OAAOK,SAAST,EAAQC,GAE1B,GAAIG,IAAO,IAAK,CACd,GAAID,GAAOH,EAAOU,IAAI,KAAM,CAC1BV,EAAOW,YACP,MAAO,OAETX,EAAOW,YACP,MAAO,UAET,GAAIP,IAAO,IAAK,CACdH,EAAMK,OAAOC,QAAQK,aACrB,OAAOH,SAAST,EAAQC,GAE1B,GAAIG,IAAO,KAAOA,IAAO,IAAK,CAC5B,MAAO,WAET,GAAIA,IAAO,IAAK,CACdJ,EAAOU,IAAI,KACXV,EAAOa,SAAS,MAChB,MAAO,YAET,GAAIT,GAAM,IAAK,CACb,GAAIJ,EAAOc,MAAM,MAAO,MAAO,WAC/B,IAAIC,EAAUf,EAAOc,MAAM,6BAC3B,GAAIC,EAAS,CACXd,EAAMK,OAAOC,QAAQS,aAAaD,EAAQ,KAC1C,MAAO,kBAGX,GAAI,KAAKE,KAAKb,GAAK,CACjBJ,EAAOa,SAAS,MAChB,GAAGb,EAAOkB,QAAU,KAAKD,KAAKjB,EAAOmB,QAAS,CAC5C,MAAO,UAGXnB,EAAOa,SAAS,SAChB,IAAIO,EAAMpB,EAAOqB,UACjB,GAAIrB,EAAOmB,SAAW,KAAO,MAAMF,KAAKG,GAAM,MAAO,MACrD,OAAO9B,MAAMgC,eAAeF,GAAO9B,MAAM8B,GAAO,KAGlD,SAASZ,YAAYe,EAAO/B,GAC1B,IAAIgC,EAAQD,GAAS,IAAM,IAAMA,GAAS,IAAM,IAAMA,EACtD,OAAO,SAASvB,EAAQC,GACtB,IAAII,EAAMoB,EAAU,MACpB,OAAQpB,EAAOL,EAAOK,SAAW,KAAM,CACrC,GAAIA,IAASmB,IAAUC,EAAS,CAC9BxB,EAAMK,OAAOoB,QACb,WACK,GAAIrB,IAAS,MAAQoB,GAAWF,IAAU,KAAOvB,EAAOmB,QAAUK,EAAO,CAC9EC,EAAU,KACVzB,EAAO2B,OAAO,GACd1B,EAAMK,OAAOC,QAAQK,aACrB,WACK,IAAKa,GAAWF,IAAUC,GAASnB,IAASkB,EAAO,CACxDtB,EAAMK,OAAOC,QAAQC,YAAYe,EAAO/B,IACxC,OAAOiB,SAAST,EAAQC,QACnB,IAAKwB,GAAW,OAAOR,KAAKZ,KAAU,OAAOY,KAAKM,GAAQ,CAC/DtB,EAAMK,OAAOC,QAAQqB,iBAAiBvB,EAAM,WAC5CL,EAAO2B,OAAO,GACd,MAEFF,GAAWA,GAAWpB,IAAS,KAEjC,OAAOb,GAIX,SAASoC,iBAAiBL,EAAO/B,GAC/B,OAAO,SAASQ,EAAQC,GACtBA,EAAMK,OAAO,GAAKE,YAAYe,EAAO/B,GACrCQ,EAAOK,OACP,OAAOI,SAAST,EAAQC,IAI5B,IAAIW,YAAc,SAASZ,EAAQC,GACjC,GAAIA,EAAMK,OAAOX,OAAS,EAAGK,EAAOU,IAAI,KACxC,IAAIN,EAAKJ,EAAOK,OAChB,GAAI,SAASY,KAAKb,GAAK,CACrBH,EAAMK,OAAO,GAAKE,YAAYJ,EAAIA,GAAM,IAAM,QAAUA,GAAM,IAAM,MAAQ,UAC5E,OAAOK,SAAST,EAAQC,GAE1B,IAAK,KAAKgB,KAAKb,GAAKJ,EAAOa,SAAS,MACpCZ,EAAMK,OAAOoB,QACb,MAAO,OAGT,SAASV,aAAaa,GACpB,OAAO,SAAS7B,EAAQC,GACtB,GAAID,EAAOG,OAASH,EAAO8B,QAAUD,EAAO5B,EAAMK,OAAOoB,QACzD1B,EAAOW,YACP,MAAO,kBAIX,SAASF,SAAST,EAAQC,GACxB,OAAQA,EAAMK,OAAO,IAAMP,WAAYC,EAAQC,GAGrC,IAAC8B,MAAQ,CACnBC,WAAY,WAAY,MAAO,CAAC1B,OAAO,KACvC2B,MAAO,SAASjC,EAAQC,GACtB,OAAOQ,SAAST,EAAQC,IAE1BiC,aAAc,CACZC,aAAcvC,YAAYwC,OAAOvC,eAAgBC,gBACjDuC,cAAe,CAACC,SAAU,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,MACpDC,cAAe,CAACC,KAAM","sourcesContent":["var words = {};\nfunction define(style, dict) {\n  for(var i = 0; i < dict.length; i++) {\n    words[dict[i]] = style;\n  }\n};\n\nvar commonAtoms = [\"true\", \"false\"];\nvar commonKeywords = [\"if\", \"then\", \"do\", \"else\", \"elif\", \"while\", \"until\", \"for\", \"in\", \"esac\", \"fi\",\n                      \"fin\", \"fil\", \"done\", \"exit\", \"set\", \"unset\", \"export\", \"function\"];\nvar commonCommands = [\"ab\", \"awk\", \"bash\", \"beep\", \"cat\", \"cc\", \"cd\", \"chown\", \"chmod\", \"chroot\", \"clear\",\n                      \"cp\", \"curl\", \"cut\", \"diff\", \"echo\", \"find\", \"gawk\", \"gcc\", \"get\", \"git\", \"grep\", \"hg\", \"kill\", \"killall\",\n                      \"ln\", \"ls\", \"make\", \"mkdir\", \"openssl\", \"mv\", \"nc\", \"nl\", \"node\", \"npm\", \"ping\", \"ps\", \"restart\", \"rm\",\n                      \"rmdir\", \"sed\", \"service\", \"sh\", \"shopt\", \"shred\", \"source\", \"sort\", \"sleep\", \"ssh\", \"start\", \"stop\",\n                      \"su\", \"sudo\", \"svn\", \"tee\", \"telnet\", \"top\", \"touch\", \"vi\", \"vim\", \"wall\", \"wc\", \"wget\", \"who\", \"write\",\n                      \"yes\", \"zsh\"];\n\ndefine('atom', commonAtoms);\ndefine('keyword', commonKeywords);\ndefine('builtin', commonCommands);\n\nfunction tokenBase(stream, state) {\n  if (stream.eatSpace()) return null;\n\n  var sol = stream.sol();\n  var ch = stream.next();\n\n  if (ch === '\\\\') {\n    stream.next();\n    return null;\n  }\n  if (ch === '\\'' || ch === '\"' || ch === '`') {\n    state.tokens.unshift(tokenString(ch, ch === \"`\" ? \"quote\" : \"string\"));\n    return tokenize(stream, state);\n  }\n  if (ch === '#') {\n    if (sol && stream.eat('!')) {\n      stream.skipToEnd();\n      return 'meta'; // 'comment'?\n    }\n    stream.skipToEnd();\n    return 'comment';\n  }\n  if (ch === '$') {\n    state.tokens.unshift(tokenDollar);\n    return tokenize(stream, state);\n  }\n  if (ch === '+' || ch === '=') {\n    return 'operator';\n  }\n  if (ch === '-') {\n    stream.eat('-');\n    stream.eatWhile(/\\w/);\n    return 'attribute';\n  }\n  if (ch == \"<\") {\n    if (stream.match(\"<<\")) return \"operator\"\n    var heredoc = stream.match(/^<-?\\s*['\"]?([^'\"]*)['\"]?/)\n    if (heredoc) {\n      state.tokens.unshift(tokenHeredoc(heredoc[1]))\n      return 'string.special'\n    }\n  }\n  if (/\\d/.test(ch)) {\n    stream.eatWhile(/\\d/);\n    if(stream.eol() || !/\\w/.test(stream.peek())) {\n      return 'number';\n    }\n  }\n  stream.eatWhile(/[\\w-]/);\n  var cur = stream.current();\n  if (stream.peek() === '=' && /\\w+/.test(cur)) return 'def';\n  return words.hasOwnProperty(cur) ? words[cur] : null;\n}\n\nfunction tokenString(quote, style) {\n  var close = quote == \"(\" ? \")\" : quote == \"{\" ? \"}\" : quote\n  return function(stream, state) {\n    var next, escaped = false;\n    while ((next = stream.next()) != null) {\n      if (next === close && !escaped) {\n        state.tokens.shift();\n        break;\n      } else if (next === '$' && !escaped && quote !== \"'\" && stream.peek() != close) {\n        escaped = true;\n        stream.backUp(1);\n        state.tokens.unshift(tokenDollar);\n        break;\n      } else if (!escaped && quote !== close && next === quote) {\n        state.tokens.unshift(tokenString(quote, style))\n        return tokenize(stream, state)\n      } else if (!escaped && /['\"]/.test(next) && !/['\"]/.test(quote)) {\n        state.tokens.unshift(tokenStringStart(next, \"string\"));\n        stream.backUp(1);\n        break;\n      }\n      escaped = !escaped && next === '\\\\';\n    }\n    return style;\n  };\n};\n\nfunction tokenStringStart(quote, style) {\n  return function(stream, state) {\n    state.tokens[0] = tokenString(quote, style)\n    stream.next()\n    return tokenize(stream, state)\n  }\n}\n\nvar tokenDollar = function(stream, state) {\n  if (state.tokens.length > 1) stream.eat('$');\n  var ch = stream.next()\n  if (/['\"({]/.test(ch)) {\n    state.tokens[0] = tokenString(ch, ch == \"(\" ? \"quote\" : ch == \"{\" ? \"def\" : \"string\");\n    return tokenize(stream, state);\n  }\n  if (!/\\d/.test(ch)) stream.eatWhile(/\\w/);\n  state.tokens.shift();\n  return 'def';\n};\n\nfunction tokenHeredoc(delim) {\n  return function(stream, state) {\n    if (stream.sol() && stream.string == delim) state.tokens.shift()\n    stream.skipToEnd()\n    return \"string.special\"\n  }\n}\n\nfunction tokenize(stream, state) {\n  return (state.tokens[0] || tokenBase) (stream, state);\n};\n\nexport const shell = {\n  startState: function() {return {tokens:[]};},\n  token: function(stream, state) {\n    return tokenize(stream, state);\n  },\n  languageData: {\n    autocomplete: commonAtoms.concat(commonKeywords, commonCommands),\n    closeBrackets: {brackets: [\"(\", \"[\", \"{\", \"'\", '\"', \"`\"]},\n    commentTokens: {line: \"#\"}\n  }\n};\n"]}